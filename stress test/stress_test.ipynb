{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORT ALL NEEDED LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEFINE STRUCTURAL METHODS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate the entropy of a vector\n",
    "# INPUTS\n",
    "# - v: vector that contains in each cell the value of a byte (so from 0 to 255)\n",
    "# - num: number of cells of the vector we want to consider in the analysis (from the first element)\n",
    "# OUTPUT: entropy value\n",
    "def entropy(v, num):\n",
    "    freq = np.zeros(256)\n",
    "    for i in range(num):\n",
    "        freq[int(v[i])]=freq[int(v[i])]+1\n",
    "    h = 0\n",
    "    for i in range(256):\n",
    "        if freq[i]>0:\n",
    "            h = h + (freq[i]/num) * np.log2(freq[i]/num)\n",
    "    h = -h\n",
    "    return h\n",
    "\n",
    "# Function to evaluate the entropy of a file as a function of the header lenght\n",
    "# INPUTS\n",
    "# - file: the file we want to anlyze (formats as an integer vector)\n",
    "# - Bytes: total number of bytes we want to consider in the analysis\n",
    "# OUTPUT: vector that contains the entropy values as a function of the header lenght analyzed\n",
    "\n",
    "def entropy_analysis(file, Bytes):\n",
    "    h_vector = np.zeros(int(Bytes/8)+1)\n",
    "    for i in range(int(Bytes/8)+1):\n",
    "        h_vector[i] = entropy(file, 8*i)\n",
    "    return h_vector\n",
    "\n",
    "# Function to evaluate the Area (DDA approach) between two files \n",
    "# INPUTS\n",
    "# - h_1,h_2: vectors obtained with entropy_analysis function\n",
    "# OUTPUT: value of the area\n",
    "def diff_area(h_1,h_2):\n",
    "    area = 0\n",
    "    length = min(len(h_1),len(h_2))\n",
    "    diff_vec = np.zeros(length)\n",
    "    for i in range(length):\n",
    "        diff_vec[i]=abs(h_1[i]-h_2[i])\n",
    "    sum = 0\n",
    "    for i in range(2,length-2):\n",
    "        sum = sum+2*diff_vec[i]\n",
    "    area = (8/2)*(diff_vec[1]+diff_vec[len(h_1)-1]+sum)\n",
    "    return area\n",
    "\n",
    "# Function to transform the file of the dataset in a vector ready to be analyzed\n",
    "# INPUTS\n",
    "# - file: the file from the dataset we want to analyze\n",
    "# - size: the size of the file we want to cut\n",
    "# OUTPUT: file vector\n",
    "def file_to_vector(file, start, offset):\n",
    "    vec = np.zeros(offset)\n",
    "    for i in range(offset):\n",
    "        vec[i] = int.from_bytes(bytes(file[start + i], 'latin-1'), byteorder=\"big\")\n",
    "    return vec\n",
    "\n",
    "# Function that compute if the file is classified as ransomware\n",
    "# INPUTS\n",
    "# - treshold: value to classify the file\n",
    "# - area: trapezoidal area of the file\n",
    "# OUTPUT: accur (correctly classified) and err (not)\n",
    "def accuracy(threshold, area):\n",
    "    accur = 0.0\n",
    "    #True positive\n",
    "    if area <= threshold:\n",
    "        accur = 1.0\n",
    "    return accur\n",
    "\n",
    "# Function that compute the differential trapezoidal area between ideal and real file\n",
    "# INPUTS\n",
    "# - ideal_file: file of 256 byte completely random\n",
    "# - file_vector: vectorialized version of the file\n",
    "# - best_hl: best header length to classify to compute the entropy, founded in best_model.ipynb\n",
    "# OUTPUT: differential area between ideal and consider file\n",
    "def trapezoidal_rule(ideal_file, file_vector, best_hl):\n",
    "    h_ideal = entropy_analysis(ideal_file, best_hl)\n",
    "    h = entropy_analysis(file_vector, best_hl)\n",
    "    return diff_area(h_ideal,h)\n",
    "\n",
    "# Function that compute the trapezoidal area of the file\n",
    "# INPUTS\n",
    "# - file: self explenatory\n",
    "# - offset: interval of byte in which compute the area\n",
    "# - best_hl: best header length to classify to compute the entropy, founded in best_model.ipynb\n",
    "# - num_frams: parameter that set the different type of analysis\n",
    "# OUTPUT: area of consider file\n",
    "def get_areas(file, offset, best_hl, num_fragms):\n",
    "    start = 0\n",
    "    i = 1\n",
    "    areas = []\n",
    "    bound = len(file) // (len(file) // offset)\n",
    "    while i <= num_fragms and len(file) >= i*offset:\n",
    "        file_vector = file\n",
    "        areas.append(trapezoidal_rule(ideal_file, file_vector, best_hl))\n",
    "        if len(file) >= (i+1)*offset and len(file) - (i+1) * bound + offset < (i+1) * bound + offset:\n",
    "            start = random.randint(i * bound, len(file) - offset)\n",
    "        elif len(file) >= (i+1)*offset and i < num_fragms-1:\n",
    "            start = random.randint(i * bound, (i+1) * bound)\n",
    "        i+=1\n",
    "    return areas\n",
    "\n",
    "# Function that update the accuracies and error statistics\n",
    "# INPUTS\n",
    "# - best_tresh: best threshold for the considere analysis, computed in best_model.ipynb\n",
    "# - sequences: length sequence value for which we are computing accuracy, used as and index for the acc matrix\n",
    "# - jumps: jump value for which we are computing accuracy, used as and index for the acc matrix\n",
    "# - acc: matrix of accuracies, also known as true positive (correctly classified ransomwares)\n",
    "# - false_negatives: matrix of ransomwares incorrecly classified as safe files\n",
    "# OUTPUT: void, just update the matrices acc and false_negatives\n",
    "def update_statistics(best_thresh, sequences, jumps, acc, best_area):\n",
    "    result = accuracy(best_thresh, best_area)\n",
    "    acc[sequences][jumps] = np.add(acc[sequences][jumps], result, dtype=float)\n",
    "\n",
    "# Function that lower the entropy of a ransomware file\n",
    "# INPUTS\n",
    "# - length_sequence: length of the random bytes sequence to insert into the file\n",
    "# - jump: distance between each injection of random bytes\n",
    "# - file: file to modify\n",
    "# OUTPUT: modified file with the requested length sequence and jump\n",
    "def modify_file(length_sequence, jump, file):\n",
    "    modified_file = []\n",
    "    for i in range(0,len(file),jump):\n",
    "        random_value = float(random.randint(0, 255))\n",
    "        random_values = [random_value for i in range(length_sequence)]\n",
    "        modified_file += list(file[i:i+jump]) + random_values\n",
    "    return modified_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GENERATE IDEAL FILE, READ FILES PATH AND INITIALYZE SEQUENCE LENGTHS AND JUMPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 256 #interval to analyze\n",
    "ideal_file = np.random.randint(0,offset,offset) #ideal random file for comparison reason\n",
    "\n",
    "# Obtains all paths to analyze from a .txt files\n",
    "f = open('../paths/path_ransomwares.txt', 'r')\n",
    "paths = f.readlines()\n",
    "f.close()\n",
    "\n",
    "sequence_start, sequence_end, sequence_step = 2,53,25 #sequence values to start, end, and step between each number\n",
    "length_sequences = np.arange(sequence_start,sequence_end,sequence_step) #generate array of such values, last values is sequence_end - 1\n",
    "jump_start, jump_end, jump_step = 2,131,128 #jump values to start, end, and step between each number\n",
    "jumps = np.arange(jump_start,jump_end,jump_step) #generate array of such values, last values is jump_end - 1\n",
    "#power = 5 #number of elements in jumps + 1, used for plot porpuses\n",
    "#jumps = np.array([12,24,32,48]) #array of jump length values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STRESS TEST FOR AVG AREA\n",
    "DEFINE AVG AREA METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that get the best area between different fragments considered\n",
    "# INPUTS\n",
    "# - distance: parameter that allows the method to mitigate the Davies effect\n",
    "# - offset: interval of byte in which compute the area\n",
    "# - areas: previously computed areas from which we pick the best one\n",
    "# - num_frams: parameter that set the different type of analysis\n",
    "# - file: considered file\n",
    "# OUTPUT: area that better perfomr for the consider analysis\n",
    "def get_best_area(distance, offset, areas, num_fragms, file):\n",
    "    best_area = 0\n",
    "    i=2\n",
    "    mean_random_area = areas[1]\n",
    "    while i < num_fragms and len(file) >= (i+1)*offset:\n",
    "        mean_random_area = mean_random_area + areas[i]\n",
    "        i+=1\n",
    "    mean_random_area = mean_random_area / (i-1)\n",
    "    if areas[0] - distance < mean_random_area:\n",
    "        best_area = areas[0]\n",
    "    else:\n",
    "        best_area = min(areas[0], mean_random_area)\n",
    "    return best_area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPLEMENT AND TEST BEST 3F_AVG MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_analyzed = 0 #total files analyzed\n",
    "num_fragms = 3 #type of analysis (3 for 3F, 4 for 4F)\n",
    "\n",
    "#initialyze results matrix\n",
    "acc = np.zeros([len(length_sequences), len(jumps)], dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve the best threshold, distance and header length values previously computed\n",
    "thresholds = np.arange(2,35,1)\n",
    "distances = np.arange(24,66,3)\n",
    "acc_des=np.load('../results/acc_3F_mix_avg.npy')\n",
    "acc_des = acc_des.reshape(len(thresholds), len(distances), int(offset/8))\n",
    "\n",
    "ind = np.unravel_index(np.argmax(acc_des, axis=None), acc_des.shape)\n",
    "best_thresh, best_dist, best_hl = thresholds[ind[0]], distances[ind[1]], 8*(ind[2]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start analysizng the directory ./NapierOneDataset/EXTRA/RANSOMWARE-MAZE-tiny\n",
      "Start analysizng the directory ./NapierOneDataset/EXTRA/RANSOMWARE-DHARMA-tiny\n",
      "Start analysizng the directory ./NapierOneDataset/EXTRA/RANSOMWARE-NETWALKER-tiny\n",
      "Start analysizng the directory ./NapierOneDataset/EXTRA/RANSOMWARE-NOTPETYA-tiny\n",
      "Start analysizng the directory ./NapierOneDataset/EXTRA/RANSOMWARE-PHOBOS-tiny\n",
      "Start analysizng the directory ./NapierOneDataset/EXTRA/RANSOMWARE-RYUK-tiny\n",
      "Start analysizng the directory ./NapierOneDataset/EXTRA/RANSOMWARE-SODINOKIBI-tiny\n",
      "Start analysizng the directory ./NapierOneDataset/EXTRA/Wannacry-tiny\n",
      "Start analysizng the directory ./NapierOneDataset/EXTRA/BadRabbit-tiny\n",
      "Time for the analysis of the dataset\n",
      "--- 7.0 minutes, 30.0 seconds, 135 files analyzed ---\n"
     ]
    }
   ],
   "source": [
    "#Perform the analysis\n",
    "start_time = time.time()\n",
    "\n",
    "# Iterate over the different directories containing files to analyze\n",
    "for j in range(len(paths)):\n",
    "    # List all the files in the paths[j] directory\n",
    "    files=os.listdir(paths[j][:-1])\n",
    "    print(\"Start analysizng the directory\", paths[j][:-1])\n",
    "    # Iterate over the different files in the directory paths[j]\n",
    "    for object in files:\n",
    "        full_path = paths[j][:-1] + \"/\" + object\n",
    "        f=open(full_path, \"r\", encoding='latin-1')\n",
    "        file = f.read()\n",
    "        file = file_to_vector(file,0,len(file))\n",
    "        for len_seq in range(len(length_sequences)):\n",
    "            for jump in range(len(jumps)):\n",
    "                modified_file = modify_file(length_sequences[len_seq],jumps[jump],file)\n",
    "                if len(modified_file) >= 2*offset:\n",
    "                    areas = get_areas(modified_file, offset, best_hl, num_fragms)\n",
    "                    best_area = get_best_area(best_dist, offset, areas, num_fragms, modified_file)\n",
    "                    update_statistics(best_thresh, len_seq,jump, acc, best_area)\n",
    "                    if(round(acc[len_seq][jump]) <= 0):\n",
    "                        break\n",
    "        files_analyzed += 1\n",
    "        f.close()\n",
    "\n",
    "acc = np.multiply(np.true_divide(acc, float(files_analyzed)), 100.0, dtype=float)\n",
    "\n",
    "time_spent = time.time() - start_time\n",
    "print(\"Time for the analysis of the dataset\")\n",
    "print(\"--- %s minutes, %s seconds, %s files analyzed ---\" % (time_spent//60, ((time_spent)-60*((time_spent)//60))//1, files_analyzed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the results\n",
    "acc = np.transpose(acc) #transpose for graphical reasons\n",
    "\n",
    "n = round((jump_end-jump_start)/jump_step) #number of curves to plot = number of jumps\n",
    "#n = power - 1 #number of curves to plot = number of jumps\n",
    "color = cm.rainbow(np.linspace(0,1,n))\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"3F_avg\")\n",
    "plt.xlabel(\"Sequence lengths\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "for i,c in zip(range(n),color):\n",
    "    label = \"Jump length \" + str(jumps[i])\n",
    "    plt.plot(length_sequences, acc[i], c=c, label=label)\n",
    "plt.legend()\n",
    "plt.ylim([0, 100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results in a file\n",
    "np.savetxt('accuracies_3F_avg_4.txt',acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPLEMENT AND TEST BEST 4F_AVG MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_analyzed = 0 #total files analyzed\n",
    "num_fragms = 4 #type of analysis (3 for 3F, 4 for 4F)\n",
    "\n",
    "#initialyze results matrix\n",
    "acc = np.zeros([len(length_sequences), len(jumps)], dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve the best threshold, distance and header length values previously computed\n",
    "thresholds = np.arange(2,35,1)\n",
    "distances = np.arange(33,66,3)\n",
    "acc_des=np.load('../results/acc_4F_mix_avg.npy')\n",
    "acc_des = acc_des.reshape(len(thresholds), len(distances), int(offset/8))\n",
    "\n",
    "ind = np.unravel_index(np.argmax(acc_des, axis=None), acc_des.shape)\n",
    "best_thresh, best_dist, best_hl = thresholds[ind[0]], distances[ind[1]], 8*(ind[2]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform the analysis\n",
    "start_time = time.time()\n",
    "\n",
    "# Iterate over the different directories containing files to analyze\n",
    "for j in range(len(paths)):\n",
    "    # List all the files in the paths[j] directory\n",
    "    files=os.listdir(paths[j][:-1])\n",
    "    print(\"Start analysizng the directory\", paths[j][:-1])\n",
    "    # Iterate over the different files in the directory paths[j]\n",
    "    for object in files:\n",
    "        full_path = paths[j][:-1] + \"/\" + object\n",
    "        f=open(full_path, \"r\", encoding='latin-1')\n",
    "        file = f.read()\n",
    "        file = file_to_vector(file,0,len(file))\n",
    "        for len_seq in range(len(length_sequences)):\n",
    "            jumps_analyzed = 0\n",
    "            for jump in range(len(jumps)):\n",
    "                modified_file = modify_file(length_sequences[len_seq],jumps[jump],file)\n",
    "                if len(modified_file) >= 2*offset:\n",
    "                    areas = get_areas(modified_file, offset, best_hl, num_fragms)\n",
    "                    best_area = get_best_area(best_dist, offset, areas, num_fragms, modified_file)\n",
    "                    update_statistics(best_thresh, len_seq,jump, acc, best_area)\n",
    "                    files_analyzed += 1\n",
    "                    jumps_analyzed += 1\n",
    "                    if(round(acc[len_seq][jump]) <= 0):\n",
    "                        break\n",
    "        f.close()\n",
    "\n",
    "acc = np.multiply(np.true_divide(acc, float(files_analyzed/(len(length_sequences)*jumps_analyzed))), 100.0, dtype=float)\n",
    "\n",
    "time_spent = time.time() - start_time\n",
    "print(\"Time for the analysis of the dataset\")\n",
    "print(\"--- %s minutes, %s seconds, %s files analyzed ---\" % (time_spent//60, ((time_spent)-60*((time_spent)//60))//1, files_analyzed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the results\n",
    "acc = np.transpose(acc) #transpose for graphical reasons\n",
    "\n",
    "n = round((jump_end-jump_start)/jump_step) #number of curves to plot = number of jumps\n",
    "#n = power - 1 #number of curves to plot = number of jumps\n",
    "color = cm.rainbow(np.linspace(0,1,n))\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"4F_avg\")\n",
    "plt.xlabel(\"Sequence length\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "for i,c in zip(range(n),color):\n",
    "    label = \"Jump length \" + str(jumps[i])\n",
    "    plt.plot(length_sequences, acc[i], c=c, label=label)\n",
    "plt.legend()\n",
    "plt.ylim([0, 100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results in a file\n",
    "np.savetxt('accuracies_4F_avg_4.txt',acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STRESS TEST FOR MAX AREA\n",
    "DEFINE MAX AREA METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that get the best area between different fragments considered\n",
    "# INPUTS\n",
    "# - distance: parameter that allows the method to mitigate the Davies effect\n",
    "# - offset: interval of byte in which compute the area\n",
    "# - areas: previously computed areas from which we pick the best one\n",
    "# - num_frams: parameter that set the different type of analysis\n",
    "# - file: considered file\n",
    "# OUTPUT: area that better perfomr for the consider analysis\n",
    "def get_best_area(distance, offset, areas, num_fragms, file):\n",
    "    best_area = 0\n",
    "    i=2\n",
    "    rand_Fs_best_area = areas[1]\n",
    "    while i < num_fragms and len(file) >= (i+1)*offset:\n",
    "        rand_Fs_best_area = max(areas[i-1], areas[i])\n",
    "        i+=1\n",
    "    if areas[0] - distance < rand_Fs_best_area:\n",
    "        best_area = areas[0]\n",
    "    else:\n",
    "        best_area = min(areas[0], rand_Fs_best_area)\n",
    "    return best_area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPLEMENT AND TEST BEST 3F_MAX MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_analyzed = 0 #total files analyzed\n",
    "num_fragms = 3 #type of analysis (3 for 3F, 4 for 4F)\n",
    "\n",
    "#initialyze results matrix\n",
    "acc = np.zeros([len(length_sequences), len(jumps)], dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve the best threshold, distance and header length values previously computed\n",
    "thresholds = np.arange(2,35,1)\n",
    "distances = np.arange(24,51,3)\n",
    "acc_des=np.load('../results/acc_3F_mix.npy')\n",
    "acc_des = acc_des.reshape(len(thresholds), len(distances), int(offset/8))\n",
    "\n",
    "ind = np.unravel_index(np.argmax(acc_des, axis=None), acc_des.shape)\n",
    "best_thresh, best_dist, best_hl = thresholds[ind[0]], distances[ind[1]], 8*(ind[2]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform the analysis\n",
    "start_time = time.time()\n",
    "\n",
    "# Iterate over the different directories containing files to analyze\n",
    "for j in range(len(paths)):\n",
    "    # List all the files in the paths[j] directory\n",
    "    files=os.listdir(paths[j][:-1])\n",
    "    print(\"Start analysizng the directory\", paths[j][:-1])\n",
    "    # Iterate over the different files in the directory paths[j]\n",
    "    for object in files:\n",
    "        full_path = paths[j][:-1] + \"/\" + object\n",
    "        f=open(full_path, \"r\", encoding='latin-1')\n",
    "        file = f.read()\n",
    "        file = file_to_vector(file,0,len(file))\n",
    "        for len_seq in range(len(length_sequences)):\n",
    "            jumps_analyzed = 0\n",
    "            for jump in range(len(jumps)):\n",
    "                modified_file = modify_file(length_sequences[len_seq],jumps[jump],file)\n",
    "                if len(modified_file) >= 2*offset:\n",
    "                    areas = get_areas(modified_file, offset, best_hl, num_fragms)\n",
    "                    best_area = get_best_area(best_dist, offset, areas, num_fragms, modified_file)\n",
    "                    update_statistics(best_thresh, len_seq,jump, acc, best_area)\n",
    "                    files_analyzed += 1\n",
    "                    jumps_analyzed += 1\n",
    "                    if(round(acc[len_seq][jump]) <= 0):\n",
    "                        break\n",
    "        f.close()\n",
    "\n",
    "acc = np.multiply(np.true_divide(acc, float(files_analyzed/(len(length_sequences)*jumps_analyzed))), 100.0, dtype=float)\n",
    "\n",
    "time_spent = time.time() - start_time\n",
    "print(\"Time for the analysis of the dataset\")\n",
    "print(\"--- %s minutes, %s seconds, %s files analyzed ---\" % (time_spent//60, ((time_spent)-60*((time_spent)//60))//1, files_analyzed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the results\n",
    "acc = np.transpose(acc) #transpose for graphical reasons\n",
    "\n",
    "n = round((jump_end-jump_start)/jump_step) #number of curves to plot = number of jumps\n",
    "#n = power - 1 #number of curves to plot = number of jumps\n",
    "color = cm.rainbow(np.linspace(0,1,n))\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"3F_max\")\n",
    "plt.xlabel(\"Sequence length\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "for i,c in zip(range(n),color):\n",
    "    label = \"Jump length \" + str(jumps[i])\n",
    "    plt.plot(length_sequences, acc[i], c=c, label=label)\n",
    "plt.legend()\n",
    "plt.ylim([0, 100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results in a file\n",
    "np.savetxt('accuracies_3F_max_4.txt',acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPLEMENT AND TEST BEST 4F_MAX MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_analyzed = 0 #total files analyzed\n",
    "num_fragms = 4 #type of analysis (3 for 3F, 4 for 4F)\n",
    "\n",
    "#initialyze results matrices\n",
    "acc = np.zeros([len(length_sequences), len(jumps)], dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve the best threshold, distance and header length values previously computed\n",
    "thresholds = np.arange(2,35,1)\n",
    "distances = np.arange(27,60,3)\n",
    "acc_des=np.load('../results/acc_4F_mix.npy')\n",
    "acc_des = acc_des.reshape(len(thresholds), len(distances), int(offset/8))\n",
    "\n",
    "ind = np.unravel_index(np.argmax(acc_des, axis=None), acc_des.shape)\n",
    "best_thresh, best_dist, best_hl = thresholds[ind[0]], distances[ind[1]], 8*(ind[2]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform the analysis\n",
    "start_time = time.time()\n",
    "\n",
    "# Iterate over the different directories containing files to analyze\n",
    "for j in range(len(paths)):\n",
    "    # List all the files in the paths[j] directory\n",
    "    files=os.listdir(paths[j][:-1])\n",
    "    print(\"Start analysizng the directory\", paths[j][:-1])\n",
    "    # Iterate over the different files in the directory paths[j]\n",
    "    for object in files:\n",
    "        full_path = paths[j][:-1] + \"/\" + object\n",
    "        f=open(full_path, \"r\", encoding='latin-1')\n",
    "        file = f.read()\n",
    "        file = file_to_vector(file,0,len(file))\n",
    "        for len_seq in range(len(length_sequences)):\n",
    "            jumps_analyzed = 0\n",
    "            for jump in range(len(jumps)):\n",
    "                modified_file = modify_file(length_sequences[len_seq],jumps[jump],file)\n",
    "                if len(modified_file) >= 2*offset:\n",
    "                    areas = get_areas(modified_file, offset, best_hl, num_fragms)\n",
    "                    best_area = get_best_area(best_dist, offset, areas, num_fragms, modified_file)\n",
    "                    update_statistics(best_thresh, len_seq,jump, acc, best_area)\n",
    "                    files_analyzed += 1\n",
    "                    jumps_analyzed += 1\n",
    "                    if(round(acc[len_seq][jump]) <= 0):\n",
    "                        break\n",
    "        f.close()\n",
    "\n",
    "acc = np.multiply(np.true_divide(acc, float(files_analyzed/(len(length_sequences)*jumps_analyzed))), 100.0, dtype=float)\n",
    "\n",
    "time_spent = time.time() - start_time\n",
    "print(\"Time for the analysis of the dataset\")\n",
    "print(\"--- %s minutes, %s seconds, %s files analyzed ---\" % (time_spent//60, ((time_spent)-60*((time_spent)//60))//1, files_analyzed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the results\n",
    "acc = np.transpose(acc) #transpose for graphical reasons\n",
    "\n",
    "n = round((jump_end-jump_start)/jump_step) #number of curves to plot = number of jumps\n",
    "#n = power - 1 #number of curves to plot = number of jumps\n",
    "color = cm.rainbow(np.linspace(0,1,n))\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"4F_max\")\n",
    "plt.xlabel(\"Sequence length\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "for i,c in zip(range(n),color):\n",
    "    label = \"Jump length \" + str(jumps[i])\n",
    "    plt.plot(length_sequences, acc[i], c=c, label=label)\n",
    "plt.legend()\n",
    "plt.ylim([0, 100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results in a file\n",
    "np.savetxt('accuracies_4F_max_4.txt',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ec1fae1e0073456d89f5f85cb0dfebaee3cdc3c5843823c35865aa8f2ef612d0"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
