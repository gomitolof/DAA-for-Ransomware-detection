{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g66qsUD0WUw9"
      },
      "source": [
        "# DEFINE GENERAL METHODS AND PARAMETERS\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ubfqCuq_hth"
      },
      "source": [
        "## IMPORT ALL NEEDED LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71uqFtZdS-k_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import cm\n",
        "import os\n",
        "import time\n",
        "from math import log, e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UA0m04OW_mlL"
      },
      "source": [
        "## DEFINE STRUCTURAL METHODS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aR44alNyS-lE"
      },
      "outputs": [],
      "source": [
        "# Function to evaluate the entropy of a vector\n",
        "# INPUTS\n",
        "# - labels: vector to compute entropy\n",
        "# - base: base of the log for the computation of entropy\n",
        "# OUTPUT: entropy values\n",
        "def compute_entropy(labels, base=None):\n",
        "\n",
        "  n_labels = len(labels)\n",
        "\n",
        "  if n_labels <= 1:\n",
        "    return 0\n",
        "\n",
        "  value,counts = np.unique(labels, return_counts=True)\n",
        "  probs = counts / n_labels\n",
        "  n_classes = np.count_nonzero(probs)\n",
        "\n",
        "  if n_classes <= 1:\n",
        "    return 0\n",
        "\n",
        "  ent = 0.\n",
        "\n",
        "  # Compute entropy\n",
        "  base = e if base is None else base\n",
        "  for i in probs:\n",
        "    ent -= i * log(i, base)\n",
        "\n",
        "  return ent\n",
        "\n",
        "# Function to evaluate the entropy of a file as a function of the header length\n",
        "# INPUTS\n",
        "# - file: the file we want to anlyze (formats as an integer vector)\n",
        "# OUTPUT: vector that contains the entropy values as a function of the header length analyzed\n",
        "\n",
        "def entropy_analysis(file):\n",
        "\n",
        "  num_bytes = int(len(file)/8)+1\n",
        "  headers_entropy = np.zeros(num_bytes)\n",
        "\n",
        "  for i in range(num_bytes):\n",
        "      headers_entropy[i] = compute_entropy(labels=file[8*i:8*(i+1)],base=2)\n",
        "\n",
        "  return headers_entropy\n",
        "\n",
        "# Function to evaluate the differential area (DDA approach) between two file's entropies \n",
        "# INPUTS\n",
        "# - file_1,file_2: vectors obtained with entropy_analysis function\n",
        "# OUTPUT: value of the differential area\n",
        "def differential_area(header_entropy_1,header_entropy_2):\n",
        "\n",
        "    length = min(len(header_entropy_1),len(header_entropy_2))\n",
        "    differential_vector = np.zeros(length)\n",
        "\n",
        "    for i in range(length):\n",
        "        differential_vector[i]=abs(header_entropy_1[i]-header_entropy_2[i])\n",
        "    \n",
        "    sum = 0\n",
        "    for i in range(1,length-1):\n",
        "        sum = sum+2*differential_vector[i]\n",
        "\n",
        "    return (8/2)*(differential_vector[0]+differential_vector[-1]+sum)\n",
        "\n",
        "# Function that evaluate if the file is classified as ransomware\n",
        "# INPUTS\n",
        "# - treshold: value to classify the file\n",
        "# - area: trapezoidal area of the file\n",
        "# OUTPUT: accur = 1.0 (correctly classified) accur = 0.0 (misclassified)\n",
        "def compute_accuracy(threshold, area):\n",
        "    accur = 0.0\n",
        "\n",
        "    #True positive (TP)\n",
        "    if area <= threshold:\n",
        "      accur = 1.0\n",
        "    \n",
        "    return accur\n",
        "\n",
        "# Function that compute the differential trapezoidal area between an ideal and a real file\n",
        "# INPUTS\n",
        "# - ideal_file: file of given bytes completely random\n",
        "# - file_vector: vectorialized version of the file, unit8 format\n",
        "# OUTPUT: differential area between ideal and consider file\n",
        "def trapezoidal_rule(file_vector, ideal_entropy):\n",
        "    file_entropy = entropy_analysis(file_vector)\n",
        "    return differential_area(file_entropy,ideal_entropy)\n",
        "\n",
        "# Function that divides the file in num_fragms segments and select a random best_hl bytes subpart from each segment\n",
        "# INPUTS\n",
        "# - file: file that we are analyzing\n",
        "# - num_frams: parameter that set the different type of analysis\n",
        "# - best_hl: best header length to classify to compute the entropy, founded in best_model.ipynb\n",
        "# - ideal_entropy: entropy of an ideal file with length best_hl previously computed\n",
        "# OUTPUT: areas of consider file\n",
        "def get_areas(file, num_fragms, best_hl, ideal_entropy):\n",
        "\n",
        "    begin = start = 0\n",
        "    i = 1\n",
        "    bound = len(file) // num_fragms\n",
        "\n",
        "    if len(file) < num_fragms * best_hl:\n",
        "        bound = len(file) // (len(file) // best_hl)\n",
        "\n",
        "    areas = []\n",
        "    while i <= num_fragms and len(file) >= i*best_hl and start < len(file) - best_hl:\n",
        "        file_vector = file[start:start+best_hl]\n",
        "        areas.append(trapezoidal_rule(file_vector,ideal_entropy))\n",
        "        begin = start + best_hl\n",
        "        if begin >= len(file) - best_hl:\n",
        "            begin = i * bound\n",
        "        if i == num_fragms and begin < len(file) - best_hl -1:\n",
        "            start = random.randint(begin, len(file) - best_hl -1)\n",
        "        else:\n",
        "            start = random.randint(begin, (i+1) * bound - best_hl)\n",
        "        i+=1\n",
        "\n",
        "    return areas\n",
        "\n",
        "# Function that update the accuracies and error statistics\n",
        "# INPUTS\n",
        "# - acc: matrix of accuracies, also known as true positive (correctly classified ransomwares)\n",
        "# - sequence_length: index of the length sequence value for which we are computing accuracy\n",
        "# - jump: index of the jump value for which we are computing accuracy\n",
        "# - best_tresh: best threshold for the considere analysis, computed in best_model.ipynb\n",
        "# - best_area : smaller area found with avg or max get_best_area methods\n",
        "# OUTPUT: void, just update the matrices acc and false_negatives\n",
        "def update_statistics(acc, sequence_length, jump, best_thresh, best_area):\n",
        "\n",
        "    result = compute_accuracy(best_thresh, best_area)\n",
        "    acc[sequence_length][jump] = acc[sequence_length][jump] + result\n",
        "\n",
        "    return\n",
        "\n",
        "# Function that lower the entropy of a ransomware file by inserting equal bytes into it\n",
        "# INPUTS\n",
        "# - file: file to modify\n",
        "# - random_values : values that will be inserted into the file\n",
        "# - sequence_length: length of the random bytes sequence to insert into the file\n",
        "# - jump: distance between each injection of random bytes\n",
        "# OUTPUT: modified file with the requested length sequence and jump\n",
        "def modify_file(file, random_values, sequence_length, jump):\n",
        "\n",
        "    modified_file = []\n",
        "\n",
        "    for i in range(0,len(file),jump):\n",
        "        modified_file += list(file[i:i+jump]) + random_values\n",
        "\n",
        "    return modified_file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lo5mbBRcFImB"
      },
      "source": [
        "## DEFINE STRESS TEST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "On4cgSgniTDE"
      },
      "outputs": [],
      "source": [
        "def perform_stress_test(stress_test_params,model_params,files_path):\n",
        "\n",
        "  sequence_lengths = stress_test_params[\"sequence_lengths\"]\n",
        "  jumps = stress_test_params[\"jumps\"]\n",
        "  acc = np.zeros([len(sequence_lengths), len(jumps)], dtype = float) #initialyze results matrix\n",
        "  files_analyzed = np.zeros([len(sequence_lengths), len(jumps)])\n",
        "  \n",
        "  #Perform the analysis\n",
        "  start_time = time.time()\n",
        "\n",
        "  print(\"Starting the analysis\")\n",
        "\n",
        "  for sequence_length in range(len(sequence_lengths)):\n",
        "\n",
        "    print(\"--- Analysis for sequence length %s ---\" % (sequence_lengths[sequence_length]))\n",
        "    time_analysis = time.time()\n",
        "    random_value = random.randint(0, 255)\n",
        "    random_values = [random_value for i in range(sequence_lengths[sequence_length])]\n",
        "\n",
        "    for jump in range(len(jumps)):\n",
        "\n",
        "      for file_path in range(len(files_path)):\n",
        "        file = np.fromfile(files_path[file_path], dtype=np.uint8)\n",
        "        modified_file = modify_file(file, random_values, sequence_lengths[sequence_length],jumps[jump])\n",
        "\n",
        "        if len(modified_file) >= model_params[\"num_fragms\"]*model_params[\"best_hl\"]:\n",
        "          areas = get_areas(modified_file,model_params[\"num_fragms\"],model_params[\"best_hl\"],model_params[\"ideal_entropy\"])\n",
        "          best_area = get_best_area(areas,model_params[\"best_dist\"])\n",
        "          update_statistics(acc,sequence_length,jump,model_params[\"best_thresh\"],best_area)\n",
        "          files_analyzed[sequence_length][jump] += 1\n",
        "\n",
        "  acc = np.multiply(np.true_divide(acc, files_analyzed), 100.0, dtype=float)\n",
        "\n",
        "  time_spent = time.time() - start_time\n",
        "  print(\"Time for the analysis of the dataset\")\n",
        "  print(\"--- %s minutes, %s seconds, %s files analyzed ---\" % (time_spent//60, ((time_spent)-60*((time_spent)//60))//1, np.sum(files_analyzed)))\n",
        "  return acc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkbz5e7nFVJd"
      },
      "source": [
        "## DEFINE PLOT RESULTS METHOD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrmtdP4JS-lX"
      },
      "outputs": [],
      "source": [
        "def plot_results(acc,stress_test_params):\n",
        "\n",
        "  acc = np.transpose(acc) #transpose for graphical reasons\n",
        "  sequence_lengths = stress_test_params[\"sequence_lengths\"]\n",
        "  jumps = stress_test_params[\"jumps\"]\n",
        "  n = len(jumps) #number of curves to plot = number of jumps\n",
        "  \n",
        "  color = cm.rainbow(np.linspace(0,1,n))\n",
        "  plt.figure(figsize=(10,10))\n",
        "  plt.title(\"3F_avg\")\n",
        "  plt.xlabel(\"Sequence lengths\")\n",
        "  plt.ylabel(\"Accuracy (%)\")\n",
        "  for i,c in zip(range(n),color):\n",
        "    label = \"Jump length \" + str(jumps[i])\n",
        "    plt.plot(sequence_lengths, acc[i], c=c, label=label)\n",
        "  plt.legend()\n",
        "  plt.ylim([0, 100])\n",
        "  plt.show()\n",
        "\n",
        "  return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svtu1__BFcSf"
      },
      "source": [
        "## CREATE LIST OF FILES' PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMpkrEob9W9I"
      },
      "outputs": [],
      "source": [
        "dataset = open('../paths/path_ransomwares.txt', 'r')\n",
        "paths = dataset.readlines()\n",
        "dataset.close()\n",
        "files_path = []\n",
        "\n",
        "for j in range(len(paths)):\n",
        "  directories = os.listdir(paths[j][:-1]) # List all the directories in the paths[j]\n",
        "  for file in range(len(directories)):\n",
        "    full_path = paths[j][:-1] + \"/\" + str(directories[file])\n",
        "    files_path.append(full_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ITSeBaiFi_v"
      },
      "source": [
        "## DEFINE PARAMS OF THE STRESS TEST: SEQUENCE LENGTHS AND JUMPS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWz_kxRFS-lK"
      },
      "outputs": [],
      "source": [
        "sequence_start, sequence_end, sequence_step = 2,129,2 #sequence values to start, end, and step between each number\n",
        "jump_start, jump_end, jump_step = 8,129,4 #jump values to start, end, and step between each number\n",
        "\n",
        "stress_test_params = {\n",
        "    \"sequence_lengths\" : np.arange(sequence_start,sequence_end,sequence_step), #generate array of such values, last values is sequence_end - 1\n",
        "    \"jumps\" : np.arange(jump_start,jump_end,jump_step) #generate array of such values, last values is jump_end - 1\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbW-7shxS-lN"
      },
      "source": [
        "# STRESS TEST FOR AVG AREA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkDdnaX3G5P8"
      },
      "source": [
        "## DEFINE AVERAGE AREA METHOD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3jkObscS-lP"
      },
      "outputs": [],
      "source": [
        "# Function that get the best area\n",
        "# INPUTS\n",
        "# - areas: previously computed areas from which we pick the best one\n",
        "# - distance: parameter that allows the method to mitigate the Davies effect\n",
        "# OUTPUT: area that better perform for the consider analysis\n",
        "def get_best_area(areas, distance):\n",
        "\n",
        "    best_area = 0\n",
        "    mean_random_area = np.mean(areas[1:])\n",
        "\n",
        "    if areas[0] - distance < mean_random_area:\n",
        "      best_area = areas[0]\n",
        "    else:\n",
        "      best_area = min(areas[0], mean_random_area)\n",
        "      \n",
        "    return best_area"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwXFEXAYY0KE"
      },
      "source": [
        "## 3F_AVG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HHELYPaHXz3"
      },
      "source": [
        "### INITIALIZE PARAMETERS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2c9t0schS-lT"
      },
      "outputs": [],
      "source": [
        "num_fragms = 3 #type of analysis (3 for 3F, 4 for 4F)\n",
        "\n",
        "#retrieve the best threshold, distance and header length values previously computed\n",
        "thresholds = np.arange(2,35,1)\n",
        "distances = np.arange(48,80,2)\n",
        "acc_des=np.load('../results/acc_3F_mix_avg.npy')\n",
        "acc_des = acc_des.reshape(len(thresholds), len(distances), int(256/8))\n",
        "\n",
        "ind = np.unravel_index(np.argmax(acc_des, axis=None), acc_des.shape)\n",
        "best_thresh, best_dist, best_hl = thresholds[ind[0]], distances[ind[1]], 8*(ind[2]+1)\n",
        "\n",
        "ideal_file = np.random.randint(0,256,best_hl) #ideal random file for comparison reason\n",
        "ideal_entropy = entropy_analysis(ideal_file) #compute entropy of ideal file with best_hl\n",
        "\n",
        "model_params = {\n",
        "    \"num_fragms\" : num_fragms,\n",
        "    \"best_thresh\" :  thresholds[ind[0]],\n",
        "    \"best_dist\" : distances[ind[1]],\n",
        "    \"best_hl\" : 8*(ind[2]+1),\n",
        "    \"ideal_entropy\": ideal_entropy\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMQNNc3cHcDl"
      },
      "source": [
        "### PERFORM THE STRESS TEST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvM9cg7eQI1s",
        "outputId": "bb3def64-d0b3-4c61-f5e9-33ecca79db76"
      },
      "outputs": [],
      "source": [
        "acc_3F_avg = perform_stress_test(stress_test_params,model_params,files_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yO5BZAq4Hqg6"
      },
      "source": [
        "### PLOT THE RESULTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dMFolURv1tL"
      },
      "outputs": [],
      "source": [
        "plot_results(acc_3F_avg,stress_test_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SERIALIZE RESULTS IN A FILE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#save results of the best are computed with avg method in a file\n",
        "np.save('../results/stress_test_acc_3F_avg.npy',acc_3F_avg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TatJaAfLciBa"
      },
      "source": [
        "## 4F_AVG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzWQbnToHy8B"
      },
      "source": [
        "### INITIALIZE PARAMETERS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6Lrkc-ZS-la"
      },
      "outputs": [],
      "source": [
        "num_fragms = 4 #type of analysis (3 for 3F, 4 for 4F)\n",
        "\n",
        "#retrieve the best threshold, distance and header length values previously computed\n",
        "thresholds = np.arange(2,35,1)\n",
        "distances = np.arange(48,80,2)\n",
        "acc_des=np.load('../results/acc_3F_mix_avg.npy')\n",
        "acc_des = acc_des.reshape(len(thresholds), len(distances), int(256/8))\n",
        "\n",
        "ind = np.unravel_index(np.argmax(acc_des, axis=None), acc_des.shape)\n",
        "best_thresh, best_dist, best_hl = thresholds[ind[0]], distances[ind[1]], 8*(ind[2]+1)\n",
        "\n",
        "ideal_file = np.random.randint(0,256,best_hl) #ideal random file for comparison reason\n",
        "ideal_entropy = entropy_analysis(ideal_file) #compute entropy of ideal file with best_hl\n",
        "\n",
        "model_params = {\n",
        "    \"num_fragms\" : num_fragms,\n",
        "    \"best_thresh\" :  thresholds[ind[0]],\n",
        "    \"best_dist\" : distances[ind[1]],\n",
        "    \"best_hl\" : 8*(ind[2]+1),\n",
        "    \"ideal_entropy\": ideal_entropy\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVP1-7fMqy-F"
      },
      "source": [
        "### PERFORM THE STRESS TEST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mq5TULEqy-I"
      },
      "outputs": [],
      "source": [
        "acc_4F_avg = perform_stress_test(stress_test_params,model_params,files_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1UOZpvHqy-J"
      },
      "source": [
        "### PLOT THE RESULTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRTs4n7Kqy-K"
      },
      "outputs": [],
      "source": [
        "plot_results(acc_4F_avg,stress_test_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SERIALIZE RESULTS IN A FILE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#save results of the best are computed with avg method in a file\n",
        "np.save('../results/stress_test_acc_4F_avg.npy',acc_4F_avg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Vw4gaWqS-lg"
      },
      "source": [
        "# STRESS TEST FOR MAX AREA\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MfvtvTcJUEY"
      },
      "source": [
        "## DEFINE MAX AREA METHOD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WotcAXRKS-lg"
      },
      "outputs": [],
      "source": [
        "# Function that get the best area between different fragments considered\n",
        "# INPUTS\n",
        "# - areas: previously computed areas from which we pick the best one\n",
        "# - distance: parameter that allows the method to mitigate the Davies effect\n",
        "# OUTPUT: area that better perfomr for the consider analysis\n",
        "def get_best_area(areas, distance):\n",
        "\n",
        "    best_area = 0\n",
        "    rand_Fs_best_area = np.amax(areas[1:])\n",
        "\n",
        "    if areas[0] - distance < rand_Fs_best_area:\n",
        "        best_area = areas[0]\n",
        "    else:\n",
        "        best_area = min(areas[0], rand_Fs_best_area)\n",
        "        \n",
        "    return best_area"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pv1j3i0tJxpA"
      },
      "source": [
        "## 3F_MAX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XORPKW3S-lh"
      },
      "source": [
        "### INITIALIZE PARAMETERS\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMwMUzw1S-li"
      },
      "outputs": [],
      "source": [
        "num_fragms = 3 #type of analysis (3 for 3F, 4 for 4F)\n",
        "\n",
        "#retrieve the best threshold, distance and header length values previously computed\n",
        "thresholds = np.arange(2,35,1)\n",
        "distances = np.arange(24,51,3)\n",
        "acc_des=np.load('../results/acc_3F_mix.npy')\n",
        "acc_des = acc_des.reshape(len(thresholds), len(distances), int(256/8))\n",
        "\n",
        "ind = np.unravel_index(np.argmax(acc_des, axis=None), acc_des.shape)\n",
        "best_thresh, best_dist, best_hl = thresholds[ind[0]], distances[ind[1]], 8*(ind[2]+1)\n",
        "\n",
        "ideal_file = np.random.randint(0,256,best_hl) #ideal random file for comparison reason\n",
        "ideal_entropy = entropy_analysis(ideal_file) #compute entropy of ideal file with best_hl\n",
        "\n",
        "model_params = {\n",
        "    \"num_fragms\" : num_fragms,\n",
        "    \"best_thresh\" :  thresholds[ind[0]],\n",
        "    \"best_dist\" : distances[ind[1]],\n",
        "    \"best_hl\" : 8*(ind[2]+1),\n",
        "    \"ideal_entropy\": ideal_entropy\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80SqaK47q3fj"
      },
      "source": [
        "### PERFORM THE STRESS TEST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mA8FlxSUq3fo"
      },
      "outputs": [],
      "source": [
        "acc_3F_max = perform_stress_test(stress_test_params,model_params,files_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbDUPax_q3ft"
      },
      "source": [
        "### PLOT THE RESULTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4Lc052zq3fv"
      },
      "outputs": [],
      "source": [
        "plot_results(acc_3F_max,stress_test_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SERIALIZE RESULTS IN A FILE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#save results of the best are computed with max method in a file\n",
        "np.save('../results/stress_test_acc_3F_max.npy',acc_3F_max)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7BrRrrQKAvw"
      },
      "source": [
        "## 4F_MAX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqpzHdF0S-lm"
      },
      "source": [
        "### INITIALIZE PARAMETERS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwi-Q5pxS-lm"
      },
      "outputs": [],
      "source": [
        "num_fragms = 4 #type of analysis (3 for 3F, 4 for 4F)\n",
        "\n",
        "#retrieve the best threshold, distance and header length values previously computed\n",
        "thresholds = np.arange(2,35,1)\n",
        "distances = np.arange(48,80,2)\n",
        "acc_des=np.load('../results/acc_4F_mix.npy')\n",
        "acc_des = acc_des.reshape(len(thresholds), len(distances), int(256/8))\n",
        "\n",
        "ind = np.unravel_index(np.argmax(acc_des, axis=None), acc_des.shape)\n",
        "best_thresh, best_dist, best_hl = thresholds[ind[0]], distances[ind[1]], 8*(ind[2]+1)\n",
        "\n",
        "ideal_file = np.random.randint(0,256,best_hl) #ideal random file for comparison reason\n",
        "ideal_entropy = entropy_analysis(ideal_file) #compute entropy of ideal file with best_hl\n",
        "\n",
        "model_params = {\n",
        "    \"num_fragms\" : num_fragms,\n",
        "    \"best_thresh\" :  thresholds[ind[0]],\n",
        "    \"best_dist\" : distances[ind[1]],\n",
        "    \"best_hl\" : 8*(ind[2]+1),\n",
        "    \"ideal_entropy\": ideal_entropy\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABpI9LWOre8N"
      },
      "source": [
        "### PERFORM THE STRESS TEST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OeobFHKre8P"
      },
      "outputs": [],
      "source": [
        "acc_4F_max = perform_stress_test(stress_test_params,model_params,files_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEg3fE8mre8Q"
      },
      "source": [
        "### PLOT THE RESULTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTWhlyQqre8R"
      },
      "outputs": [],
      "source": [
        "plot_results(acc_4F_max,stress_test_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0PPMU8wKP_S"
      },
      "source": [
        "### SERIALIZE RESULTS IN A FILE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "of7UJgnjS-lq"
      },
      "outputs": [],
      "source": [
        "#save results of the best are computed with max method in a file\n",
        "np.save('../results/stress_test_acc_4F_max.npy',acc_4F_max)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "stress_test.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "f3829f2c1eece7dd9fdaa5b0dbec02962a23d51361b4e4655008413bd4e44011"
    },
    "kernelspec": {
      "display_name": "Python 3.10.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
